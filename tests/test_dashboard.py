"""
ğŸ“Š Testmodul fÃ¼r Fairness-Dashboard-Daten (`test_dashboard.py`)

Dieses Testmodul Ã¼berprÃ¼ft die IntegritÃ¤t und GÃ¼ltigkeit der von der Fairness-Pipeline 
erzeugten Metrikdateien â€“ insbesondere der Datei `fairness_metrics.csv` â€“ die typischerweise 
von einem Analyse-Dashboard (z.â€¯B. Streamlit, Dash) visualisiert werden.

TestÃ¼bersicht:
--------------
1. `test_fairness_file_loads`:
   - Validiert, ob die Datei `fairness_metrics.csv` erfolgreich geladen werden kann
     und die erwarteten SchlÃ¼sselspalten wie `Klasse` und `DemographicParityDifference` enthÃ¤lt.

2. `test_metric_ranges`:
   - Stellt sicher, dass die Werte in der Spalte `DemographicParityDifference`
     im erwarteten Wertebereich (zwischen -1.0 und 1.0) liegen und valide sind.

Fixtures:
---------
- `fairness_df`: LÃ¤dt einmalig die Metrikdatei und stellt sie allen Tests zur VerfÃ¼gung.

Verwendete Technologien:
------------------------
- `pytest`: Test-Framework fÃ¼r einfache, lesbare TestfÃ¤lle
- `pandas`: Datenverarbeitung und numerische Validierung
- `pathlib`, `sys`: Dynamische Pfadanpassung zum Importieren von Modulen aus `src`
- `locale`, `json`, `os`: Reserviert/importiert, aber in diesem Scope aktuell ungenutzt

Einsatzkontext:
---------------
Diese Tests dienen der QualitÃ¤tssicherung im Rahmen eines Fairness-Dashboards oder zur 
automatisierten Auswertung von Evaluationsergebnissen in CI/CD-Pipelines.

Autor: Bettina Gertjerenken, Dagmar Wesemann, Kai W. Steffen
Stand: Juni 2025
"""
# tests/test_fairness_analysis_flow.py
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

# tests/test_dashboard.py
import pytest
import os
import json
import pandas as pd
import locale
import logging
import warnings

warnings.filterwarnings("ignore", category=FutureWarning, message=".*palette.*without assigning.*hue.*is deprecated.*")

logging.getLogger("streamlit").setLevel(logging.ERROR)

# # FÃ¼ge das 'src'-Verzeichnis zum Python-Pfad hinzu
# src_path = Path(__file__).parent.parent / 'src'
# sys.path.insert(0, str(src_path))


# Fixture zum Laden des Fairness-Metrik-Datensatzes aus der Ergebnisdatei
@pytest.fixture
def fairness_df():
    """
    LÃ¤dt die Fairness-Metrikdatei (CSV) und gibt sie als DataFrame zurÃ¼ck.
    Wird als Fixture fÃ¼r alle Tests verwendet, die auf die Metriken zugreifen.
    """
    df = pd.read_csv("results/fairness_metrics.csv")
    return df

##############################
# tests/test_metric_visualization.py
import pytest
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from fairness_dashboard import interpretationen    
from fairness_dashboard import get_readable_class_label   



@pytest.fixture
def demo_df():
    """
    Erstellt ein Beispiel-DataFrame mit Dummy-Fairnessmetriken fÃ¼r Visualisierungstests.
    Wird fÃ¼r Plot- und Mapping-Tests verwendet.
    """
    data = {
        "DemographicParityDifference": [0.1, 0.25, -0.05],
        "EqualizedOddsDifference": [0.05, 0.22, 0.01]
    }
    df = pd.DataFrame(data)
    df.index = [0, 1, 2]
    return df


@pytest.mark.parametrize("metric", ["DemographicParityDifference", "EqualizedOddsDifference"])
def test_metric_exists_and_numeric(demo_df, metric):
    """
    PrÃ¼ft, ob die angegebene Metrikspalte im DataFrame existiert und numerische Werte enthÃ¤lt.
    """
    assert metric in demo_df.columns, f"âŒ Spalte '{metric}' fehlt"
    converted = pd.to_numeric(demo_df[metric], errors="coerce")
    assert not converted.isna().all(), f"âŒ Alle Werte in '{metric}' sind ungÃ¼ltig"


def test_label_mapping_is_string(demo_df):
    """
    Testet, ob die Label-Mapping-Funktion fÃ¼r jeden Index einen nicht-leeren String zurÃ¼ckgibt.
    """
    labels = demo_df.index.map(get_readable_class_label)
    for label in labels:
        assert isinstance(label, str)
        assert len(label) > 0


@pytest.mark.parametrize("metric", ["DemographicParityDifference"])
def test_can_generate_barplot(demo_df, metric):
    """
    ÃœberprÃ¼ft, ob fÃ¼r die angegebene Metrik ein Balkendiagramm ohne Fehler erzeugt werden kann.
    """
    demo_df = demo_df.copy()
    demo_df["Label"] = demo_df.index.map(get_readable_class_label)
    threshold = 0.2

    # Plot erstellen
    fig, ax = plt.subplots(figsize=(10, 5))
    try:
        sns.barplot(x="Label", y=metric, data=demo_df, palette="viridis", ax=ax)
        ax.axhline(threshold, color="red", linestyle="--")
    except Exception as e:
        pytest.fail(f"âŒ Fehler beim Erzeugen des Plots: {e}")



########################
def test_fairness_file_loads(fairness_df):
    """
    PrÃ¼ft, ob die Fairness-Metrikdatei geladen werden kann und die erwarteten Spalten enthÃ¤lt.
    Gibt die geladenen Spalten zur Kontrolle aus.
    """
    print("ğŸ” ÃœberprÃ¼fe, ob Datei geladen werden konnte...")
    print(f"ğŸ“¦ Geladene Spalten: {list(fairness_df.columns)}")

    assert "Klasse" in fairness_df.columns, "âŒ Spalte 'Klasse' fehlt in der CSV-Datei."
    assert "DemographicParityDifference" in fairness_df.columns, "âŒ Spalte 'DemographicParityDifference' fehlt in der CSV-Datei."

    print("âœ… Datei enthÃ¤lt alle erforderlichen Spalten.\n")


def test_metric_ranges(fairness_df):
    """
    ÃœberprÃ¼ft, ob die Werte fÃ¼r 'DemographicParityDifference' gÃ¼ltig und im erwarteten Bereich sind.
    Gibt Wertebereich und Anzahl gÃ¼ltiger Werte aus.
    """
    print("ğŸ“ ÃœberprÃ¼fe Wertebereich fÃ¼r 'DemographicParityDifference'...")
    dpd_vals = pd.to_numeric(fairness_df["DemographicParityDifference"], errors="coerce")

    print(f"ğŸ”¢ GÃ¼ltige Werte gefunden: {dpd_vals.count()}/{len(dpd_vals)}")
    print(f"ğŸ§® Wertebereich: min={dpd_vals.min():.3f}, max={dpd_vals.max():.3f}")

    assert dpd_vals.isna().sum() < len(dpd_vals), "âŒ Alle DPD-Werte sind ungÃ¼ltig oder fehlen."
    assert dpd_vals.max() < 1.0, f"âŒ HÃ¶chstwert Ã¼berschreitet 1.0: {dpd_vals.max():.3f}"

    print("âœ… Alle Metriken liegen im erwarteten Bereich.\n")


