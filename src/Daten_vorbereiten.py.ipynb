{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a0fc41-1a05-433a-89d3-365b5da23af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Nur die ersten 5 Zeilen einlesen\n",
    "df_preview = pd.read_csv(r'C:\\Users\\kaiws\\Downloads\\311_Service_Requests_from_2010_to_Present_20250621.csv', nrows=5)\n",
    "\n",
    "# Spaltennamen anzeigen\n",
    "print(\"Spaltennamen:\")\n",
    "print(df_preview.columns)\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Erste 5 Zeilen anzeigen\n",
    "print(\"Erste 5 Zeilen:\")\n",
    "print(df_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f1dbb-f8f7-40be-b418-62161ba01461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Gewünschte Spalten\n",
    "selected_columns = ['Created Date', 'Closed Date', 'Agency', 'Complaint Type', \n",
    "                   'Descriptor', 'Location Type', 'Incident Zip', 'Borough','Vehicle Type','Location']\n",
    "\n",
    "# Dateipfad\n",
    "csv_path = r'C:\\Users\\kaiws\\Downloads\\311_Service_Requests_from_2010_to_Present_20250621.csv'\n",
    "\n",
    "# Liste für gefilterte Daten\n",
    "filtered_data = []\n",
    "\n",
    "# Zähler für Gesamtstatistik\n",
    "total_rows = 0\n",
    "filtered_rows = 0\n",
    "\n",
    "# Chunkweise einlesen und filtern\n",
    "chunk_size = 100000  # 100k Zeilen pro Chunk\n",
    "\n",
    "for chunk in pd.read_csv(csv_path, \n",
    "                        usecols=selected_columns, \n",
    "                        chunksize=chunk_size,\n",
    "                        low_memory=False):\n",
    "    \n",
    "    # Datums-Spalten konvertieren mit explizitem Format\n",
    "    chunk['Created Date'] = pd.to_datetime(chunk['Created Date'], \n",
    "                                         format='%m/%d/%Y %I:%M:%S %p', \n",
    "                                         errors='coerce')\n",
    "    chunk['Closed Date'] = pd.to_datetime(chunk['Closed Date'], \n",
    "                                        format='%m/%d/%Y %I:%M:%S %p', \n",
    "                                        errors='coerce')\n",
    "    \n",
    "    # Gesamtanzahl aktualisieren\n",
    "    total_rows += len(chunk)\n",
    "    \n",
    "    # Filter: Nur Jahre 2022, 2023, 2024\n",
    "    year_filter = chunk['Created Date'].dt.year.isin([2022, 2023, 2024])\n",
    "    \n",
    "    # Filter: Closed Date darf nicht leer sein\n",
    "    closed_date_filter = chunk['Closed Date'].notna()\n",
    "    \n",
    "    # Kombinierte Filter anwenden\n",
    "    filtered_chunk = chunk[year_filter & closed_date_filter]\n",
    "    \n",
    "    # Gefilterte Anzahl aktualisieren\n",
    "    filtered_rows += len(filtered_chunk)\n",
    "    \n",
    "    # Gefilterte Daten zur Liste hinzufügen\n",
    "    filtered_data.append(filtered_chunk)\n",
    "    \n",
    "    # Fortschritt anzeigen\n",
    "    print(f\"Chunk verarbeitet: {len(chunk)} Zeilen gelesen, {len(filtered_chunk)} Zeilen gefiltert\")\n",
    "\n",
    "# Alle gefilterten Chunks zusammenführen\n",
    "df_filtered = pd.concat(filtered_data, ignore_index=True)\n",
    "\n",
    "# Gefilterte Daten speichern\n",
    "df_filtered.to_csv(r'C:\\Users\\kaiws\\Downloads\\filtered_311_data_2022-2024_pycaret_new.csv', index=False))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"GESAMTSTATISTIK:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Gesamtanzahl Datensätze in der CSV: {total_rows:,}\")\n",
    "print(f\"Gefilterte Datensätze (2022-2024, mit Closed Date): {filtered_rows:,}\")\n",
    "print(f\"Entfernte Datensätze: {total_rows - filtered_rows:,}\")\n",
    "print(f\"Filterrate: {((total_rows - filtered_rows) / total_rows * 100):.1f}% der Daten entfernt\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\"\\nFinale Datenmenge: {len(df_filtered)} Zeilen\")\n",
    "print(f\"Spalten: {list(df_filtered.columns)}\")\n",
    "\n",
    "# Erste Zeilen anzeigen\n",
    "print(\"\\nErste 5 Zeilen:\")\n",
    "print(df_filtered.head())\n",
    "\n",
    "# Jahresverteilung anzeigen\n",
    "print(\"\\nJahresverteilung:\")\n",
    "print(df_filtered['Created Date'].dt.year.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4178a11-1589-460d-ae56-206999a24574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Korrekter Pfad zu den gefilterten Daten\n",
    "csv_path = r'C:\\Users\\kaiws\\Downloads\\filtered_311_data_2022-2024_pycaret_new.csv'\n",
    "\n",
    "# Daten laden (mit low_memory=False um Warnung zu vermeiden)\n",
    "df_filtered = pd.read_csv(csv_path, low_memory=False)\n",
    "print(\"Daten erfolgreich geladen!\")\n",
    "\n",
    "# Analyse der Complaint Types\n",
    "print(\"ANALYSE DER COMPLAINT TYPES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Gesamtzahl der unterschiedlichen Complaint Types\n",
    "total_unique_complaints = df_filtered['Complaint Type'].nunique()\n",
    "print(f\"Gesamtzahl unterschiedlicher Complaint Types: {total_unique_complaints:,}\")\n",
    "\n",
    "# Häufigste 30 Complaint Types\n",
    "top_30_complaints = df_filtered['Complaint Type'].value_counts().head(30)\n",
    "\n",
    "print(f\"\\nDie 30 häufigsten Complaint Types:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Mit Index (Rang) und Prozentangabe\n",
    "for i, (complaint_type, count) in enumerate(top_30_complaints.items(), 1):\n",
    "    percentage = (count / len(df_filtered)) * 100\n",
    "    print(f\"{i:2d}. {complaint_type:<40} {count:>8,} ({percentage:5.1f}%)\")\n",
    "\n",
    "# Zusätzliche Statistiken\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"ZUSÄTZLICHE STATISTIKEN:\")\n",
    "print(f\"Gesamtzahl Datensätze: {len(df_filtered):,}\")\n",
    "print(f\"Durchschnittliche Häufigkeit pro Complaint Type: {len(df_filtered) / total_unique_complaints:,.0f}\")\n",
    "print(f\"Complaint Types mit nur 1 Eintrag: {(df_filtered['Complaint Type'].value_counts() == 1).sum()}\")\n",
    "print(f\"Complaint Types mit ≤ 10 Einträgen: {(df_filtered['Complaint Type'].value_counts() <= 10).sum()}\")\n",
    "\n",
    "# VISUALISIERUNG\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"VISUALISIERUNG:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Top 10 Complaint Types als Balkendiagramm\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Daten für Visualisierung vorbereiten\n",
    "top_10_complaints = df_filtered['Complaint Type'].value_counts().head(10)\n",
    "\n",
    "# Balkendiagramm erstellen (KORRIGIERT - ohne Warnung)\n",
    "sns.barplot(x=top_10_complaints.values, y=top_10_complaints.index, color='steelblue')\n",
    "\n",
    "plt.title('Top 10 Complaint Types (2022-2024)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Anzahl der Service Requests', fontsize=12)\n",
    "plt.ylabel('Complaint Type', fontsize=12)\n",
    "\n",
    "# Werte auf den Balken anzeigen\n",
    "for i, v in enumerate(top_10_complaints.values):\n",
    "    plt.text(v + max(top_10_complaints.values) * 0.01, i, f'{v:,}', \n",
    "             va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Zusätzlich: Verteilung als Tortendiagramm (Top 5)\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_5_complaints = df_filtered['Complaint Type'].value_counts().head(5)\n",
    "other_complaints = df_filtered['Complaint Type'].value_counts().iloc[5:].sum()\n",
    "\n",
    "# Daten für Tortendiagramm vorbereiten\n",
    "pie_data = pd.concat([top_5_complaints, pd.Series({'Sonstige': other_complaints})])\n",
    "\n",
    "plt.pie(pie_data.values, labels=pie_data.index, autopct='%1.1f%%', startangle=90)\n",
    "plt.title('Verteilung der Complaint Types (Top 5 vs. Sonstige)', fontsize=14, fontweight='bold')\n",
    "plt.axis('equal')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c58f38-8b8e-452c-861b-e912db6c5d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfe ob df_filtered existiert\n",
    "if 'df_filtered' in locals():\n",
    "    print(\"df_filtered existiert und wird verwendet.\")\n",
    "    print(f\"Anzahl Zeilen: {len(df_filtered):,}\")\n",
    "else:\n",
    "    print(\"df_filtered existiert nicht. Lade Daten neu...\")\n",
    "    # Lade Daten neu\n",
    "    csv_path = r'C:\\Users\\kaiws\\Downloads\\filtered_311_data_2022-2024_pycaret_new.csv'\n",
    "    df_filtered = pd.read_csv(csv_path, low_memory=False)\n",
    "    print(\"Daten geladen!\")\n",
    "\n",
    "# Top 30 Complaint Types identifizieren\n",
    "top_30_complaint_types = df_filtered['Complaint Type'].value_counts().head(30).index\n",
    "\n",
    "print(f\"Anzahl Complaint Types vor Filterung: {df_filtered['Complaint Type'].nunique():,}\")\n",
    "print(f\"Anzahl Datensätze vor Filterung: {len(df_filtered):,}\")\n",
    "\n",
    "# Nur Zeilen mit den Top 30 Complaint Types behalten\n",
    "df_filtered_top30 = df_filtered[df_filtered['Complaint Type'].isin(top_30_complaint_types)].copy()\n",
    "\n",
    "print(f\"\\nAnzahl Complaint Types nach Filterung: {df_filtered_top30['Complaint Type'].nunique():,}\")\n",
    "print(f\"Anzahl Datensätze nach Filterung: {len(df_filtered_top30):,}\")\n",
    "print(f\"Entfernte Datensätze: {len(df_filtered) - len(df_filtered_top30):,}\")\n",
    "print(f\"Behaltene Daten: {((len(df_filtered_top30) / len(df_filtered)) * 100):.1f}%\")\n",
    "\n",
    "# Überprüfung: Zeige die Top 30 Complaint Types\n",
    "print(f\"\\nDie 30 häufigsten Complaint Types (die behalten wurden):\")\n",
    "print(\"-\" * 60)\n",
    "for i, complaint_type in enumerate(top_30_complaint_types, 1):\n",
    "    count = df_filtered_top30[df_filtered_top30['Complaint Type'] == complaint_type].shape[0]\n",
    "    print(f\"{i:2d}. {complaint_type}\")\n",
    "\n",
    "# Gefilterte Daten speichern\n",
    "output_path = r'C:\\Users\\kaiws\\Downloads\\filtered_311_data_top30.csv'\n",
    "df_filtered_top30.to_csv(output_path, index=False)\n",
    "print(f\"\\nGefilterte Daten gespeichert in: {output_path}\")\n",
    "\n",
    "# Aktualisiere df_filtered für weitere Analysen\n",
    "df_filtered = df_filtered_top30.copy()\n",
    "print(\"\\nDataFrame 'df_filtered' wurde mit den Top 30 Complaint Types aktualisiert!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pycaret_new]",
   "language": "python",
   "name": "conda-env-pycaret_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
